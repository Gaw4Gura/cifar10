{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mini_goog_le_net_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_unit_171 (ConvUnit)     multiple                  3072      \n",
      "_________________________________________________________________\n",
      "mini_inception_72 (MiniIncep multiple                  31040     \n",
      "_________________________________________________________________\n",
      "mini_inception_73 (MiniIncep multiple                  30096     \n",
      "_________________________________________________________________\n",
      "down_sampling_18 (DownSampli multiple                  58000     \n",
      "_________________________________________________________________\n",
      "mini_inception_74 (MiniIncep multiple                  87840     \n",
      "_________________________________________________________________\n",
      "mini_inception_75 (MiniIncep multiple                  108320    \n",
      "_________________________________________________________________\n",
      "mini_inception_76 (MiniIncep multiple                  128800    \n",
      "_________________________________________________________________\n",
      "mini_inception_77 (MiniIncep multiple                  146640    \n",
      "_________________________________________________________________\n",
      "down_sampling_19 (DownSampli multiple                  187344    \n",
      "_________________________________________________________________\n",
      "mini_inception_78 (MiniIncep multiple                  467088    \n",
      "_________________________________________________________________\n",
      "mini_inception_79 (MiniIncep multiple                  544656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  3370      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  110       \n",
      "=================================================================\n",
      "Total params: 1,796,376\n",
      "Trainable params: 1,792,856\n",
      "Non-trainable params: 3,520\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/70\n",
      "50000/50000 [==============================] - 179s 4ms/sample - loss: 1.8105 - accuracy: 0.4009 - val_loss: 1.3700 - val_accuracy: 0.5791\n",
      "Epoch 2/70\n",
      "50000/50000 [==============================] - 173s 3ms/sample - loss: 1.4336 - accuracy: 0.5560 - val_loss: 1.1575 - val_accuracy: 0.6650\n",
      "Epoch 3/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 1.2585 - accuracy: 0.6227 - val_loss: 1.0404 - val_accuracy: 0.7017\n",
      "Epoch 4/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 1.1475 - accuracy: 0.6668 - val_loss: 0.9490 - val_accuracy: 0.7536\n",
      "Epoch 5/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 1.0630 - accuracy: 0.7000 - val_loss: 0.9291 - val_accuracy: 0.7581\n",
      "Epoch 6/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.9854 - accuracy: 0.7319 - val_loss: 0.9111 - val_accuracy: 0.7694\n",
      "Epoch 7/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.9337 - accuracy: 0.7521 - val_loss: 0.7829 - val_accuracy: 0.8164\n",
      "Epoch 8/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.8748 - accuracy: 0.7759 - val_loss: 0.7597 - val_accuracy: 0.8191\n",
      "Epoch 9/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.8293 - accuracy: 0.7936 - val_loss: 0.7918 - val_accuracy: 0.8170\n",
      "Epoch 10/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.8035 - accuracy: 0.8042 - val_loss: 0.8028 - val_accuracy: 0.8169\n",
      "Epoch 11/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.7619 - accuracy: 0.8183 - val_loss: 0.7782 - val_accuracy: 0.8251\n",
      "Epoch 12/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.7392 - accuracy: 0.8264 - val_loss: 0.7716 - val_accuracy: 0.8354\n",
      "Epoch 13/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.7058 - accuracy: 0.8416 - val_loss: 0.7535 - val_accuracy: 0.8385\n",
      "Epoch 14/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.6900 - accuracy: 0.8472 - val_loss: 0.7526 - val_accuracy: 0.8449\n",
      "Epoch 15/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.6658 - accuracy: 0.8563 - val_loss: 0.8259 - val_accuracy: 0.8239\n",
      "Epoch 16/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.6467 - accuracy: 0.8668 - val_loss: 0.7855 - val_accuracy: 0.8351\n",
      "Epoch 17/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.6283 - accuracy: 0.8714 - val_loss: 0.8571 - val_accuracy: 0.8233\n",
      "Epoch 18/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.6223 - accuracy: 0.8740 - val_loss: 0.7983 - val_accuracy: 0.8465\n",
      "Epoch 19/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5982 - accuracy: 0.8818 - val_loss: 0.8033 - val_accuracy: 0.8458\n",
      "Epoch 20/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5890 - accuracy: 0.8870 - val_loss: 0.8191 - val_accuracy: 0.8512\n",
      "Epoch 21/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5713 - accuracy: 0.8927 - val_loss: 0.9041 - val_accuracy: 0.8344\n",
      "Epoch 22/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5640 - accuracy: 0.8972 - val_loss: 0.8854 - val_accuracy: 0.8430\n",
      "Epoch 23/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5583 - accuracy: 0.8989 - val_loss: 0.9001 - val_accuracy: 0.8357\n",
      "Epoch 24/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.5440 - accuracy: 0.9050 - val_loss: 0.8278 - val_accuracy: 0.8541\n",
      "Epoch 25/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5295 - accuracy: 0.9103 - val_loss: 0.8970 - val_accuracy: 0.8450\n",
      "Epoch 26/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5253 - accuracy: 0.9121 - val_loss: 0.8997 - val_accuracy: 0.8485\n",
      "Epoch 27/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.5252 - accuracy: 0.9140 - val_loss: 0.8717 - val_accuracy: 0.8527\n",
      "Epoch 28/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.5010 - accuracy: 0.9190 - val_loss: 0.9176 - val_accuracy: 0.8533\n",
      "Epoch 29/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4924 - accuracy: 0.9225 - val_loss: 0.9271 - val_accuracy: 0.8485\n",
      "Epoch 30/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4915 - accuracy: 0.9252 - val_loss: 0.9458 - val_accuracy: 0.8483\n",
      "Epoch 31/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.4932 - accuracy: 0.9236 - val_loss: 0.8617 - val_accuracy: 0.8596\n",
      "Epoch 32/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.4685 - accuracy: 0.9307 - val_loss: 0.9501 - val_accuracy: 0.8465\n",
      "Epoch 33/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4737 - accuracy: 0.9302 - val_loss: 1.0045 - val_accuracy: 0.8379\n",
      "Epoch 34/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.4648 - accuracy: 0.9323 - val_loss: 0.8976 - val_accuracy: 0.8613\n",
      "Epoch 35/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4484 - accuracy: 0.9373 - val_loss: 0.9137 - val_accuracy: 0.8535\n",
      "Epoch 36/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4614 - accuracy: 0.9311 - val_loss: 0.9681 - val_accuracy: 0.8482\n",
      "Epoch 37/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4406 - accuracy: 0.9394 - val_loss: 1.0124 - val_accuracy: 0.8517\n",
      "Epoch 38/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4362 - accuracy: 0.9395 - val_loss: 0.9402 - val_accuracy: 0.8587\n",
      "Epoch 39/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4292 - accuracy: 0.9413 - val_loss: 0.9717 - val_accuracy: 0.8582\n",
      "Epoch 40/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4226 - accuracy: 0.9445 - val_loss: 0.9795 - val_accuracy: 0.8551\n",
      "Epoch 41/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4078 - accuracy: 0.9480 - val_loss: 1.0710 - val_accuracy: 0.8547\n",
      "Epoch 42/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.4040 - accuracy: 0.9470 - val_loss: 0.9427 - val_accuracy: 0.8667\n",
      "Epoch 43/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3943 - accuracy: 0.9507 - val_loss: 0.9827 - val_accuracy: 0.8584\n",
      "Epoch 44/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3918 - accuracy: 0.9516 - val_loss: 0.9620 - val_accuracy: 0.8631\n",
      "Epoch 45/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3919 - accuracy: 0.9499 - val_loss: 0.9641 - val_accuracy: 0.8657\n",
      "Epoch 46/70\n",
      "50000/50000 [==============================] - 174s 3ms/sample - loss: 0.3736 - accuracy: 0.9553 - val_loss: 0.9709 - val_accuracy: 0.8637\n",
      "Epoch 47/70\n",
      "50000/50000 [==============================] - 175s 4ms/sample - loss: 0.3749 - accuracy: 0.9545 - val_loss: 0.9907 - val_accuracy: 0.8601\n",
      "Epoch 48/70\n",
      "50000/50000 [==============================] - 172s 3ms/sample - loss: 0.3666 - accuracy: 0.9556 - val_loss: 0.9931 - val_accuracy: 0.8657\n",
      "Epoch 49/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3570 - accuracy: 0.9583 - val_loss: 0.9287 - val_accuracy: 0.8700\n",
      "Epoch 50/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3519 - accuracy: 0.9590 - val_loss: 0.9769 - val_accuracy: 0.8659\n",
      "Epoch 51/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3468 - accuracy: 0.9594 - val_loss: 0.9332 - val_accuracy: 0.8707\n",
      "Epoch 52/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3341 - accuracy: 0.9628 - val_loss: 0.9610 - val_accuracy: 0.8715\n",
      "Epoch 53/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3311 - accuracy: 0.9633 - val_loss: 0.9894 - val_accuracy: 0.8687\n",
      "Epoch 54/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3311 - accuracy: 0.9628 - val_loss: 0.9853 - val_accuracy: 0.8724\n",
      "Epoch 55/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3173 - accuracy: 0.9659 - val_loss: 0.9365 - val_accuracy: 0.8744\n",
      "Epoch 56/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3122 - accuracy: 0.9677 - val_loss: 0.9743 - val_accuracy: 0.8760\n",
      "Epoch 57/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3093 - accuracy: 0.9688 - val_loss: 0.9978 - val_accuracy: 0.8703\n",
      "Epoch 58/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3014 - accuracy: 0.9699 - val_loss: 0.9424 - val_accuracy: 0.8753\n",
      "Epoch 59/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.3004 - accuracy: 0.9699 - val_loss: 0.9604 - val_accuracy: 0.8794\n",
      "Epoch 60/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2973 - accuracy: 0.9705 - val_loss: 0.9591 - val_accuracy: 0.8782\n",
      "Epoch 61/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2923 - accuracy: 0.9708 - val_loss: 0.9471 - val_accuracy: 0.8818\n",
      "Epoch 62/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2873 - accuracy: 0.9717 - val_loss: 0.9393 - val_accuracy: 0.8829\n",
      "Epoch 63/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2832 - accuracy: 0.9731 - val_loss: 0.9516 - val_accuracy: 0.8799\n",
      "Epoch 64/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2811 - accuracy: 0.9735 - val_loss: 0.9571 - val_accuracy: 0.8800\n",
      "Epoch 65/70\n",
      "50000/50000 [==============================] - 174s 3ms/sample - loss: 0.2794 - accuracy: 0.9736 - val_loss: 0.9561 - val_accuracy: 0.8786\n",
      "Epoch 66/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2779 - accuracy: 0.9743 - val_loss: 0.9546 - val_accuracy: 0.8792\n",
      "Epoch 67/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2774 - accuracy: 0.9737 - val_loss: 0.9544 - val_accuracy: 0.8816\n",
      "Epoch 68/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2755 - accuracy: 0.9739 - val_loss: 0.9511 - val_accuracy: 0.8801\n",
      "Epoch 69/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2723 - accuracy: 0.9749 - val_loss: 0.9480 - val_accuracy: 0.8805\n",
      "Epoch 70/70\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 0.2756 - accuracy: 0.9748 - val_loss: 0.9494 - val_accuracy: 0.8805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, metrics, regularizers\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "\n",
    "tf.random.set_seed(1119001)\n",
    "\n",
    "class ConvUnit(keras.Model):\n",
    "    def __init__(self, channels, ksize, strides = 1, padding = \"same\"):\n",
    "        super(ConvUnit, self).__init__()\n",
    "        \n",
    "        self.model = keras.models.Sequential([\n",
    "            layers.Conv2D(channels, kernel_size = ksize, strides = strides, padding = padding, kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4), activation = 'relu'),\n",
    "            layers.BatchNormalization(),\n",
    "        ])\n",
    "        \n",
    "    def call(self, x, training = None):\n",
    "        x = self.model(x, training = training)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class MiniInception(keras.Model):\n",
    "    def __init__(self, params):\n",
    "        super(MiniInception, self).__init__()\n",
    "        \n",
    "        (ch1, ch2) = params\n",
    "        \n",
    "        self.conv1x1 = ConvUnit(ch1, ksize = (1, 1))\n",
    "        self.conv3x3 = ConvUnit(ch2, ksize = (3, 3))\n",
    "        \n",
    "    def call(self, x, training = None):\n",
    "        res1 = self.conv1x1(x, training = training)\n",
    "        res2 = self.conv3x3(x, training = training)\n",
    "        \n",
    "        return tf.concat([res1, res2], axis = -1)\n",
    "    \n",
    "class DownSampling(keras.Model):\n",
    "    def __init__(self, channels):\n",
    "        super(DownSampling, self).__init__()\n",
    "        \n",
    "        self.conv = ConvUnit(channels, ksize = (3, 3), strides = 2, padding = \"valid\")\n",
    "        self.pool = layers.MaxPooling2D(pool_size = (3, 3), strides = 2, padding = \"valid\")\n",
    "        \n",
    "    def call(self, x, training = None):\n",
    "        res1 = self.conv(x, training = training)\n",
    "        res2 = self.pool(x)\n",
    "        \n",
    "        return tf.concat([res1, res2], axis = -1)\n",
    "    \n",
    "class MiniGoogLeNet(keras.Model):\n",
    "    def __init__(self, classes, **kwargs):\n",
    "        super(MiniGoogLeNet, self).__init__()\n",
    "        \n",
    "        self.conv = ConvUnit(channels = 96, ksize = (3, 3))\n",
    "        \n",
    "        self.inception3a = MiniInception((32, 32))\n",
    "        self.inception3b = MiniInception((32, 48))\n",
    "        self.downsampling1 = DownSampling(80)\n",
    "        \n",
    "        self.inception4a = MiniInception((112, 48))\n",
    "        self.inception4b = MiniInception((96, 64))\n",
    "        self.inception4c = MiniInception((80, 80))\n",
    "        self.inception4d = MiniInception((48, 96))\n",
    "        self.downsampling2 = DownSampling(144)\n",
    "        \n",
    "        self.inception5a = MiniInception((176, 160))\n",
    "        self.inception5b = MiniInception((176, 160))\n",
    "        self.flatten = layers.GlobalAveragePooling2D()\n",
    "        self.dropout1 = layers.Dropout(0.4)\n",
    "        \n",
    "        self.fc = layers.Dense(classes)\n",
    "        self.dropout2 = layers.Dropout(0.4)\n",
    "        self.softmax = layers.Dense(classes, activation = 'softmax')\n",
    "                \n",
    "    def call(self, x, training = None):\n",
    "        x = self.conv(x, training = training)\n",
    "        \n",
    "        x = self.inception3a(x, training = training)\n",
    "        x = self.inception3b(x, training = training)\n",
    "        x = self.downsampling1(x, training = training)\n",
    "        \n",
    "        x = self.inception4a(x, training = training)\n",
    "        x = self.inception4b(x, training = training)\n",
    "        x = self.inception4c(x, training = training)\n",
    "        x = self.inception4d(x, training = training)\n",
    "        x = self.downsampling2(x, training = training)\n",
    "        \n",
    "        x = self.inception5a(x, training = training)\n",
    "        x = self.inception5b(x, training = training)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc(x, training = training)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.softmax(x, training = training)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "mean_train = np.mean(x_train, axis = 0)\n",
    "x_train = x_train - mean_train\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "mean_test = np.mean(x_test, axis = 0)\n",
    "x_test = x_test - mean_test\n",
    "\n",
    "def one_hot(y, depth):\n",
    "    res = np.zeros((len(y), depth))\n",
    "    \n",
    "    for i, label in enumerate(y):\n",
    "        \n",
    "        res[i, label] = 1\n",
    "        \n",
    "    return res\n",
    "\n",
    "y_train = one_hot(y_train, depth = 10)\n",
    "y_test = one_hot(y_test, depth = 10)\n",
    "\n",
    "EPOCHS = 200\n",
    "INIT_LR = 0.01\n",
    "\n",
    "def poly_decay(epoch):\n",
    "    maxEpochs = EPOCHS\n",
    "    baseLR = INIT_LR\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "callbacks = [keras.callbacks.LearningRateScheduler(poly_decay)]\n",
    "\n",
    "def main():\n",
    "    model = MiniGoogLeNet(10)\n",
    "    model.build(input_shape = (None, 32, 32, 3))\n",
    "    model.summary()\n",
    "    \n",
    "    keras.utils.plot_model(model, to_file = 'MiniGooLeNet.png', show_shapes = True)\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.SGD(lr = INIT_LR, momentum = 0.9, nesterov = True), metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 32, epochs = EPOCHS, callbacks = callbacks)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
